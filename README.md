# Gender and Representation Bias in GPT-3 Generated Stories

This README is ordered according to sections in the paper, and each section describes corresponding scripts and materials involved in their production. 

## Abstract
Using topic modeling and lexicon-based word similarity, we find that stories generated by GPT-3 exhibit many known gender stereotypes. Generated stories depict different topics and descriptions depending on GPT-3's perceived gender of the character in a prompt, with feminine characters more likely to be associated with family and appearance, and described as less powerful than masculine characters, even when associated with high power verbs in a prompt. Our study raises questions on how one can avoid unintended social biases when using large language models for storytelling.

## Requirements 

TBD by workshop date 

## Text Processing 

### Gender 

### Matching

## Topics

## Lexicons

TBD by workshop date 

Code is also currently being cleaned up and commented 
